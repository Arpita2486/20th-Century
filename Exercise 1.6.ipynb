{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3823272d-efac-48d7-ab38-c23551712b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, unicodedata, itertools, collections\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# spaCy for NER\n",
    "try:\n",
    "    import spacy\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except Exception as e:\n",
    "    print(\"spaCy model 'en_core_web_sm' not found. Install with:\\n  python -m spacy download en_core_web_sm\")\n",
    "    import spacy\n",
    "    nlp = None\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path(\".\").resolve()\n",
    "DATA_PATH = PROJECT_ROOT / \"key_events_20th_century_text.txt\"   # adjust if needed\n",
    "OUT_DIR = PROJECT_ROOT / \"outputs\" / \"Exercise_1_6\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root : {PROJECT_ROOT}\")\n",
    "print(f\"Data path    : {DATA_PATH} (exists: {DATA_PATH.exists()})\")\n",
    "print(f\"Output dir   : {OUT_DIR}\")\n",
    "\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(\"Could not find 'key_events_20th_century_text.txt' at project root. Update DATA_PATH if needed.\")\n",
    "\n",
    "raw_text = DATA_PATH.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "print(f\"Loaded {len(raw_text):,} characters.\\n\")\n",
    "print(raw_text[:800] + \"\\n...\")\n",
    "\n",
    "def non_ascii_report(text, top_n=25):\n",
    "    non_ascii = [c for c in text if ord(c) > 127]\n",
    "    counts = collections.Counter(non_ascii).most_common(top_n)\n",
    "    return counts\n",
    "\n",
    "def basic_clean(text: str) -> str:\n",
    "    # Unicode normalization\n",
    "    x = unicodedata.normalize(\"NFKC\", text)\n",
    "\n",
    "    # Replace common unicode punctuation with ASCII equivalents\n",
    "    replacements = {\n",
    "        \"\\u2018\": \"'\", \"\\u2019\": \"'\", \"\\u201C\": '\"', \"\\u201D\": '\"',\n",
    "        \"\\u2013\": \"-\", \"\\u2014\": \"-\", \"\\u00A0\": \" \", \"\\u2026\": \"...\",\n",
    "    }\n",
    "    for k, v in replacements.items():\n",
    "        x = x.replace(k, v)\n",
    "\n",
    "    # Collapse whitespace\n",
    "    x = re.sub(r\"[ \\t]+\", \" \", x)\n",
    "    x = re.sub(r\"\\s+\\n\", \"\\n\", x)\n",
    "    x = re.sub(r\"\\n{3,}\", \"\\n\\n\", x).strip()\n",
    "    return x\n",
    "\n",
    "print(\"Top non-ASCII chars BEFORE cleaning:\", non_ascii_report(raw_text))\n",
    "clean_text = basic_clean(raw_text)\n",
    "print(\"Top non-ASCII chars AFTER  cleaning:\", non_ascii_report(clean_text))\n",
    "\n",
    "CLEAN_PATH = OUT_DIR / \"key_events_20th_century_text_clean.txt\"\n",
    "CLEAN_PATH.write_text(clean_text, encoding=\"utf-8\")\n",
    "print(f\"\\nSaved cleaned text to: {CLEAN_PATH}\")\n",
    "\n",
    "user_list = None\n",
    "for fn in [\"countries_list.txt\", \"countries.txt\"]:\n",
    "    p = Path(fn)\n",
    "    if p.exists():\n",
    "        try:\n",
    "            user_list = [line.strip() for line in p.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines() if line.strip()]\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load {fn}: {e}\")\n",
    "\n",
    "if user_list:\n",
    "    CANON_COUNTRIES = sorted(set(user_list))\n",
    "    print(f\"Loaded {len(CANON_COUNTRIES)} countries from your file.\")\n",
    "else:\n",
    "    CANON_COUNTRIES = sorted({\n",
    "        # Major & frequently-mentioned (edit as needed)\n",
    "        \"United States\",\"United Kingdom\",\"France\",\"Germany\",\"Italy\",\"Spain\",\"Portugal\",\n",
    "        \"Russia\",\"Soviet Union\",\"China\",\"Japan\",\"India\",\"Pakistan\",\"Canada\",\"Australia\",\n",
    "        \"Poland\",\"Czechoslovakia\",\"Yugoslavia\",\"Austria\",\"Hungary\",\"Netherlands\",\"Belgium\",\n",
    "        \"Switzerland\",\"Sweden\",\"Norway\",\"Denmark\",\"Finland\",\"Ireland\",\"Greece\",\"Turkey\",\n",
    "        \"Israel\",\"Palestine\",\"Egypt\",\"Iran\",\"Iraq\",\"Syria\",\"Lebanon\",\"Jordan\",\"Saudi Arabia\",\n",
    "        \"Korea\",\"North Korea\",\"South Korea\",\"Vietnam\",\"North Vietnam\",\"South Vietnam\",\"Taiwan\",\n",
    "        \"Czech Republic\",\"Slovakia\",\"East Germany\",\"West Germany\",\n",
    "        \"Brazil\",\"Argentina\",\"Mexico\",\"Cuba\",\"Chile\",\"Peru\",\"Colombia\",\n",
    "        \"South Africa\",\"Ethiopia\",\"Kenya\",\"Nigeria\",\"Ghana\",\"Algeria\",\"Morocco\",\n",
    "        # Historical empires/states that may appear\n",
    "        \"Ottoman Empire\",\"Austro-Hungarian Empire\",\"Russian Empire\",\"Prussia\"\n",
    "    })\n",
    "    print(f\"Using built-in canonical list: {len(CANON_COUNTRIES)} countries.\")\n",
    "\n",
    "# Synonyms/variants → canonical\n",
    "COUNTRY_SYNONYMS = {\n",
    "    # US/UK\n",
    "    \"u.s.\":\"United States\",\"u.s\":\"United States\",\"u.s.a.\":\"United States\",\"usa\":\"United States\",\"us\":\"United States\",\"america\":\"United States\",\n",
    "    \"united states of america\":\"United States\",\n",
    "    \"u.k.\":\"United Kingdom\",\"uk\":\"United Kingdom\",\"great britain\":\"United Kingdom\",\"britain\":\"United Kingdom\",\"england\":\"United Kingdom\",\n",
    "    # Russia/USSR\n",
    "    \"ussr\":\"Soviet Union\",\"soviet russia\":\"Soviet Union\",\"russian empire\":\"Russian Empire\",\n",
    "    # Germany\n",
    "    \"german empire\":\"Germany\",\"prussian empire\":\"Prussia\",\"west germany\":\"West Germany\",\"east germany\":\"East Germany\",\n",
    "    # China/Taiwan\n",
    "    \"prc\":\"China\",\"people's republic of china\":\"China\",\"peoples republic of china\":\"China\",\"republic of china\":\"Taiwan\",\"roc\":\"Taiwan\",\n",
    "    # Korea/Vietnam\n",
    "    \"korean peninsula\":\"Korea\",\"dprk\":\"North Korea\",\"rok\":\"South Korea\",\n",
    "    \"democratic republic of vietnam\":\"North Vietnam\",\"republic of vietnam\":\"South Vietnam\",\n",
    "    # Other common variants\n",
    "    \"czechia\":\"Czech Republic\",\"holland\":\"Netherlands\",\"ivory coast\":\"Ivory Coast\"\n",
    "}\n",
    "\n",
    "def canonicalize_country(name: str):\n",
    "    \"\"\"Map a raw entity string to a canonical country name if possible.\"\"\"\n",
    "    if not name:\n",
    "        return None\n",
    "    s = re.sub(r\"[^\\w\\s\\-&\\.']\", \" \", name.lower()).strip()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    if s in COUNTRY_SYNONYMS:\n",
    "        return COUNTRY_SYNONYMS[s]\n",
    "    # Title-case fallback (e.g., \"France\", \"Soviet Union\")\n",
    "    t = re.sub(r\"\\s+\", \" \", name.strip())\n",
    "    return t\n",
    "\n",
    "if nlp is None:\n",
    "    raise RuntimeError(\"spaCy language model not loaded. Run: python -m spacy download en_core_web_sm\")\n",
    "\n",
    "doc = nlp(clean_text)\n",
    "print(f\"Document length (tokens): {len(doc)}\")\n",
    "print(\"Sample entities:\", [(ent.text, ent.label_) for ent in doc.ents[:15]])\n",
    "\n",
    "sentence_entities = []   # list of tuples: (sentence_text, [entity_texts])\n",
    "for sent in doc.sents:\n",
    "    ents = [ent for ent in sent.ents if ent.label_ in (\"GPE\",\"LOC\")]\n",
    "    if ents:\n",
    "        sentence_entities.append((sent.text, [e.text for e in ents]))\n",
    "\n",
    "print(f\"Sentences with (GPE/LOC) entities: {len(sentence_entities)}\")\n",
    "print(\"Example:\", sentence_entities[0] if sentence_entities else \"No sentences with GPE/LOC found.\")\n",
    "\n",
    "filtered_sentences = []  # (sentence_text, [canonical_country_names])\n",
    "for sent_text, ents in sentence_entities:\n",
    "    canon = []\n",
    "    for e in ents:\n",
    "        c = canonicalize_country(e)\n",
    "        if c in CANON_COUNTRIES:\n",
    "            canon.append(c)\n",
    "    canon = sorted(set(canon))  # unique within sentence\n",
    "    if canon:\n",
    "        filtered_sentences.append((sent_text, canon))\n",
    "\n",
    "print(f\"Sentences with recognized countries (canonical): {len(filtered_sentences)}\")\n",
    "if filtered_sentences:\n",
    "    print(\"Example:\", filtered_sentences[0])\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6) Build Relationships (country–country co-occurrence per sentence)\n",
    "\n",
    "# %%\n",
    "pairs = []\n",
    "for _, countries in filtered_sentences:\n",
    "    if len(countries) >= 2:\n",
    "        for a, b in itertools.combinations(sorted(countries), 2):\n",
    "            pairs.append((a, b))\n",
    "\n",
    "print(f\"Total raw pairs: {len(pairs)}\")\n",
    "\n",
    "# %%\n",
    "# Aggregate counts into a DataFrame\n",
    "if pairs:\n",
    "    df_pairs = pd.DataFrame(pairs, columns=[\"country1\",\"country2\"])\n",
    "    df_rel = df_pairs.value_counts().reset_index(name=\"weight\")\n",
    "else:\n",
    "    df_rel = pd.DataFrame(columns=[\"country1\",\"country2\",\"weight\"])\n",
    "\n",
    "df_rel.head()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7) Save & Export Outputs\n",
    "\n",
    "# %%\n",
    "# Save relationships CSV\n",
    "REL_CSV = OUT_DIR / \"country_relationships.csv\"\n",
    "df_rel.to_csv(REL_CSV, index=False, encoding=\"utf-8\")\n",
    "print(f\"Saved relationships to: {REL_CSV} (rows: {len(df_rel)})\")\n",
    "\n",
    "# Clean text already saved earlier at CLEAN_PATH\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8) Sanity Checks & Notes\n",
    "#\n",
    "# - Inspect `country_relationships.csv` for reasonable pairs (e.g., “United States”–“United Kingdom”, “Germany”–“France”, etc.).  \n",
    "# - If you see unexpected names (e.g., cities being treated as countries), extend the **synonyms** or tighten the **canonical list**.  \n",
    "# - If Exercise 1.5 produced a final countries list, place it as `countries_list.txt` in the project root (one per line) and rerun this notebook to use it.\n",
    "#\n",
    "# **Next (Exercise 1.7):** Use `country_relationships.csv` to create the network visualization (nodes=countries, edges weighted by co-occurrence).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (20th_century)",
   "language": "python",
   "name": "20th_century"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
